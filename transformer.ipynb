{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11de7399",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea7ce401",
   "metadata": {},
   "source": [
    "# 1. Multi-Head Attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7cc2dfa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, dim_num=512, head_num=8):\n",
    "        super().__init__()\n",
    "        self.head_num = head_num\n",
    "        self.dim_num = dim_num\n",
    "        \n",
    "        self.query_embed = nn.Linear(dim_num, dim_num)\n",
    "        self.key_embed = nn.Linear(dim_num, dim_num)\n",
    "        self.value_embed = nn.Linear(dim_num, dim_num)\n",
    "        self.output_embed = nn.Linear(dim_num, dim_num)\n",
    "    \n",
    "    # q, k Shape (Batch X Head_num X token_length X hidden)\n",
    "    # q는 현재 token을 embedding\n",
    "    # k는 문장 전체의 token을 embedding\n",
    "    # output = 문장 내에 어느 token에 주의를 기울일지 선택\n",
    "    def scaled_dot_product_attention(self, q, k, v, mask=None):\n",
    "        d_k = k.size()[-1]\n",
    "        k_transpose = torch.transpose(k, 3, 2)\n",
    "\n",
    "        output = torch.matmul(q, k_transpose)\n",
    "        output = output/math.sqrt(d_k)\n",
    "        if mask is not None:\n",
    "            output = output.masked_fill(mask.unsqueeze(1).unsqueeze(-1), 0)\n",
    "\n",
    "        output = F.softmax(output, -1)\n",
    "        output = torch.matmul(output, v)\n",
    "\n",
    "        return output\n",
    "    \n",
    "    def forward(self, q, k, v, mask=None):\n",
    "        batch_size = q.size()[0]\n",
    "        \n",
    "        # 순서 유지 때문에 view 후 transpose 사용\n",
    "        q = self.query_embed(q).view(batch_size, -1, self.head_num, self.dim_num//self.head_num).transpose(1,2)\n",
    "        k = self.key_embed(k).view(batch_size, -1, self.head_num, self.dim_num//self.head_num).transpose(1,2)\n",
    "        v = self.value_embed(v).view(batch_size, -1, self.head_num, self.dim_num//self.head_num).transpose(1,2)\n",
    "        \n",
    "        output = self.scaled_dot_product_attention(q,k,v,mask)\n",
    "        batch_num, head_num, seq_num, hidden_num = output.size()\n",
    "        output = torch.transpose(output, 1, 2).contiguous().view((batch_size, -1, hidden_num*self.head_num))\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36703759",
   "metadata": {},
   "source": [
    "# 2. Residual Add & Layer Norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9caeb8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddLayerNorm(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def layer_norm(self, input):\n",
    "        mean = torch.mean(input, dim=-1, keepdim=True)\n",
    "        std = torch.std(input, dim =-1, keepdim=True)\n",
    "        output = (input-mean)/std\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    def forward(self, input, residual):\n",
    "        return residual+self.layer_norm(input)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17cb921",
   "metadata": {},
   "source": [
    "# 3. Feed Forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e5331f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "    def __init__(self, dim_num=512):\n",
    "        super().__init__()\n",
    "        self.layer1 = nn.Linear(dim_num, dim_num*4)\n",
    "        self.layer2 = nn.Linear(dim_num*4, dim_num)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        output = self.layer1(input)\n",
    "        output = self.layer2(F.relu(output))\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eeaea964",
   "metadata": {},
   "source": [
    "# 4. Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24b812c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, dim_num=512):\n",
    "        super().__init__()\n",
    "        self.multihead = MultiHeadAttention(dim_num=dim_num)\n",
    "        self.residual_layer1 = AddLayerNorm()\n",
    "        self.feed_forward = FeedForward(dim_num=dim_num)\n",
    "        self.residual_layer2 = AddLayerNorm()\n",
    "        \n",
    "    def forward(self, q, k, v):\n",
    "        multihead_output = self.multihead(q,k,v)\n",
    "        residual1_output = self.residual_layer1(multihead_output, q)\n",
    "        feedforward_output = self.feed_forward(residual1_output)\n",
    "        output = self.residual_layer2(feedforward_output, residual1_output)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5a7b94",
   "metadata": {},
   "source": [
    "# 5. Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75701077",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, dim_num = 512):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.masked_multihead = MultiHeadAttention(dim_num=dim_num)\n",
    "        self.residual_layer1 = AddLayerNorm()\n",
    "        self.multihead = MultiHeadAttention(dim_num=dim_num)\n",
    "        self.residual_layer2 = AddLayerNorm()\n",
    "        self.feed_forward = FeedForward(dim_num=dim_num)\n",
    "        self.residual_layer3 = AddLayerNorm()\n",
    "        \n",
    "    def forward(self, o_q, o_k, o_v, encoder_output, mask):\n",
    "        masked_multihead_output = self.masked_multihead(o_q, o_k, o_v, mask)\n",
    "        residual1_output = self.residual_layer1(masked_multihead_output, o_q)\n",
    "        multihead_output = self.multihead(encoder_output, encoder_output, residual1_output, mask)\n",
    "        residual2_output = self.residual_layer2(multihead_output, residual1_output)\n",
    "        feedforward_output = self.feed_forward(residual2_output)\n",
    "        output = self.residual_layer3(feedforward_output, residual2_output)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33829970",
   "metadata": {},
   "source": [
    "# 6. Transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a368946f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(self, encoder_num=6, decoder_num=6, hidden_dim=512,\n",
    "                 max_encoder_seq_length=100, max_decoder_seq_length=100):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder_num = encoder_num\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.max_encoder_seq_length = max_encoder_seq_length\n",
    "        self.max_decoder_seq_length = max_decoder_seq_length\n",
    "        \n",
    "        self.input_data_embed = nn.Embedding(max_seq_length, self.hidden_dim)\n",
    "        self.Encoders = nn.ModuleList([Encoder(dim_num=hidden_dim) for _ in range(encoder_num)])\n",
    "        \n",
    "        self.output_data_embed = nn.Embedding(max_seq_length, self.hidden_dim)\n",
    "        self.Decoders = nn.ModuleList([Decoder(dim_num=hidden_dim) for _ in range(decoder_num)])\n",
    "        \n",
    "        self.last_linear_layer = nn.Linear(self.hidden_dim, max_seq_length)\n",
    "        \n",
    "    def position_encoding(self, seq_len, max_len):\n",
    "        position = torch.arange(0, seq_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, self.hidden_dim, 2).float() * (-math.log(10000.0) / self.hidden_dim))\n",
    "        pe = torch.zeros(1, seq_len, self.hidden_dim)\n",
    "        pe[0, :, 0::2] = torch.sin(position * div_term)\n",
    "        pe[0, :, 1::2] = torch.cos(position * div_term)\n",
    "        return pe\n",
    "    \n",
    "    def forward(self, input, output, mask):\n",
    "        input_embed = self.input_data_embed(input)\n",
    "        input_seq_len = input.size(1)\n",
    "        input_embed += self.position_encoding(input_seq_len, self.max_encoder_seq_length).to(input.device)\n",
    "        q, k, v = input_embed, input_embed, input_embed\n",
    "        \n",
    "        for encoder in self.Encoders:\n",
    "            encoder_output = encoder(q, k, v)\n",
    "            q = encoder_output\n",
    "            k = encoder_output\n",
    "            v = encoder_output\n",
    "            \n",
    "        output_embed = self.output_data_embed(output)\n",
    "        output_seq_len = output.size(1)\n",
    "        output_embed += self.position_encoding(output_seq_len, self.max_decoder_seq_length).to(output.device)\n",
    "        output_embed = output_embed.masked_fill(mask.unsqueeze(-1) == 0, 0)\n",
    "        d_q, d_k, d_v = output_embed, output_embed, output_embed\n",
    "        \n",
    "        for decoder in self.Decoders:\n",
    "            decoder_output = decoder(d_q, d_k, d_v, encoder_output, mask)\n",
    "            d_q = decoder_output\n",
    "            d_k = decoder_output\n",
    "            d_v = decoder_output\n",
    "        \n",
    "        output = self.last_linear_layer(decoder_output)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5d22d3d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 100])\n"
     ]
    }
   ],
   "source": [
    "# 모델 사용 예시\n",
    "max_seq_length = 100\n",
    "model = Transformer(max_encoder_seq_length=max_seq_length, max_decoder_seq_length=max_seq_length)\n",
    "input = torch.randint(low=0, high=max_seq_length, size=(64, max_seq_length), dtype=torch.long)\n",
    "output = torch.randint(low=0, high=max_seq_length, size=(64, max_seq_length), dtype=torch.long)\n",
    "mask = torch.zeros((64, max_seq_length))\n",
    "mask[:, :30] = 1\n",
    "\n",
    "output = model(input, output, mask)\n",
    "_, pred = torch.max(output, dim=-1)\n",
    "print(pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b21de180",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9d4d888",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
